{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6146ad",
   "metadata": {},
   "source": [
    "# Creating a RAG (Retrieval-Augmented Generation) System with LangChain and Mistral\n",
    "\n",
    "Welcome! This notebook demonstrates how to build a RAG system using [LangChain](https://python.langchain.com/) and the [Mistral API](https://docs.mistral.ai/). \n",
    "\n",
    "**What is RAG?**\n",
    "- RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with language generation.\n",
    "- It allows LLMs to access and utilize external knowledge sources by retrieving relevant documents and using them to inform responses.\n",
    "- This enables more accurate, up-to-date, and contextually relevant answers beyond the model's training data.\n",
    "\n",
    "**Notebook Goals:**\n",
    "- Show how to set up a RAG system powered by Mistral.\n",
    "- Demonstrate document loading, embedding, and retrieval.\n",
    "- Build a question-answering system that can answer questions based on your documents.\n",
    "- Align with the agentic workflow patterns discussed in the tutorial: *Agents and Agentic Workflows with LLMs - Complete Tutorial* (see README.md).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91ec30",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies\n",
    "\n",
    "Let's start by installing the required libraries for our RAG system. We'll need document loaders for various file formats, embedding models, vector databases, and the Mistral API integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ada83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-mistralai in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.11)\n",
      "Collecting langchain-core<1.0.0,>=0.3.68 (from langchain-mistralai)\n",
      "  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-mistralai) (0.21.2)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-mistralai) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-mistralai) (0.4.1)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-mistralai) (2.9.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai)\n",
      "  Using cached langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-mistralai) (2.23.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.33.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.66.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (0.4.6)\n",
      "Using cached langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Using cached langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.147\n",
      "    Uninstalling langsmith-0.1.147:\n",
      "      Successfully uninstalled langsmith-0.1.147\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.63\n",
      "    Uninstalling langchain-core-0.3.63:\n",
      "      Successfully uninstalled langchain-core-0.3.63\n",
      "Successfully installed langchain-core-0.3.68 langsmith-0.4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.0 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.4.5 which is incompatible.\n",
      "langchain-community 0.3.0 requires langsmith<0.2.0,>=0.1.112, but you have langsmith 0.4.5 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement getpass (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for getpass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
      "Using cached langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.4.5\n",
      "    Uninstalling langsmith-0.4.5:\n",
      "      Successfully uninstalled langsmith-0.4.5\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.68\n",
      "    Uninstalling langchain-core-0.3.68:\n",
      "      Successfully uninstalled langchain-core-0.3.68\n",
      "Successfully installed langchain-core-0.3.63 langsmith-0.1.147\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-mistralai 0.2.11 requires langchain-core<1.0.0,>=0.3.68, but you have langchain-core 0.3.63 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (6.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dekamb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (uncomment if running in a new environment)\n",
    "%pip install langchain-mistralai\n",
    "%pip install python-dotenv\n",
    "%pip install getpass\n",
    "%pip install langchain\n",
    "%pip install langchain-community\n",
    "%pip install pypdf\n",
    "%pip install python-docx\n",
    "%pip install faiss-cpu\n",
    "%pip install sentence-transformers\n",
    "%pip install tiktoken\n",
    "%pip install jq\n",
    "\n",
    "# Note: If running in a managed environment (like VS Code or JupyterHub),\n",
    "# you may need to restart the kernel after installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cb9903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral API key loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load API keys securely\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "# Load environment variables from a .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "\n",
    "# If not found, prompt the user securely\n",
    "if not MISTRAL_API_KEY:\n",
    "    MISTRAL_API_KEY = getpass('Enter your Mistral API key: ')\n",
    "\n",
    "# Confirm that the key is loaded (do not print the key!)\n",
    "if MISTRAL_API_KEY:\n",
    "    print('‚úÖ Mistral API key loaded.')\n",
    "else:\n",
    "    raise ValueError('‚ùå Mistral API key not found. Please set it in your .env file or enter it when prompted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b92bff",
   "metadata": {},
   "source": [
    "## 2. Configure Mistral LLM in LangChain\n",
    "\n",
    "Next, we'll set up the Mistral LLM using LangChain's integration. We'll use the `mistral-medium` model, but you can choose others as needed. This step connects LangChain to the Mistral API using your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4fb948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral LLM configured with model: mistral-medium\n"
     ]
    }
   ],
   "source": [
    "# Configure the Mistral LLM in LangChain\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "# Choose the model (see Mistral docs for available options)\n",
    "MISTRAL_MODEL = \"mistral-medium\"  # You can change this to another available model\n",
    "\n",
    "# Set up the LLM wrapper\n",
    "llm = ChatMistralAI(\n",
    "    api_key=MISTRAL_API_KEY,\n",
    "    model=MISTRAL_MODEL,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mistral LLM configured with model: {MISTRAL_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db93e7",
   "metadata": {},
   "source": [
    "## 3. Load Documents from Knowledgebase\n",
    "\n",
    "For RAG to work, we need to load documents from various sources. We'll create a flexible document loading system that can handle multiple file formats including text, PDF, Word documents, JSON, and CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27295ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'knowledgebase' not found. Creating sample documents...\n",
      "‚úÖ Created sample documents in knowledgebase/\n",
      "‚ùå Error loading sample.json: jq package not found, please install it with `pip install jq`\n",
      "‚úÖ Loaded 1 documents from sample.txt\n",
      "\n",
      "üìö Total documents loaded: 1\n",
      "\n",
      "üìÑ First document preview:\n",
      "Source: knowledgebase\\sample.txt\n",
      "Content (first 300 chars): \n",
      "        Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artificial intelligence agents.\n",
      "        \n",
      "        What are AI Agents?\n",
      "        AI agents are autonomous systems that can perceive their environment,\n",
      "        make decisions, and take actions to achieve...\n"
     ]
    }
   ],
   "source": [
    "# Import document loaders\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    "    JSONLoader,\n",
    "    CSVLoader,\n",
    "    DirectoryLoader\n",
    ")\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load documents from various formats\n",
    "def load_documents_from_directory(directory_path=\"knowledgebase\"):\n",
    "    \"\"\"\n",
    "    Load documents from a directory containing various file formats.\n",
    "    Supports: .txt, .pdf, .docx, .json, .csv files\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory '{directory_path}' not found. Creating sample documents...\")\n",
    "        create_sample_documents(directory_path)\n",
    "    \n",
    "    # Load different file types\n",
    "    file_loaders = {\n",
    "        '.txt': TextLoader,\n",
    "        '.pdf': PyPDFLoader,\n",
    "        '.docx': Docx2txtLoader,\n",
    "        '.json': JSONLoader,\n",
    "        '.csv': CSVLoader\n",
    "    }\n",
    "    \n",
    "    for file_path in Path(directory_path).glob('*'):\n",
    "        if file_path.suffix.lower() in file_loaders:\n",
    "            try:\n",
    "                loader_class = file_loaders[file_path.suffix.lower()]\n",
    "                if file_path.suffix.lower() == '.json':\n",
    "                    # Try different JSON loading approaches\n",
    "                    try:\n",
    "                        # Method 1: Use jq_schema (requires jq package)\n",
    "                        loader = loader_class(str(file_path), jq_schema='.', text_content=False)\n",
    "                    except ImportError:\n",
    "                        # Method 2: Fallback to simple JSON loading\n",
    "                        print(f\"‚ö†Ô∏è  jq package not found, using simple JSON loading for {file_path.name}\")\n",
    "                        loader = loader_class(str(file_path))\n",
    "                else:\n",
    "                    loader = loader_class(str(file_path))\n",
    "                \n",
    "                docs = loader.load()\n",
    "                documents.extend(docs)\n",
    "                print(f\"‚úÖ Loaded {len(docs)} documents from {file_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {file_path.name}: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def create_sample_documents(directory_path):\n",
    "    \"\"\"Create sample documents for demonstration if they don't exist\"\"\"\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    \n",
    "    # Sample text document\n",
    "    with open(f\"{directory_path}/sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\"\"\n",
    "        Welcome to the AI Agents Tutorial!\n",
    "        \n",
    "        This document contains information about artificial intelligence agents.\n",
    "        \n",
    "        What are AI Agents?\n",
    "        AI agents are autonomous systems that can perceive their environment,\n",
    "        make decisions, and take actions to achieve specific goals.\n",
    "        \n",
    "        Types of AI Agents:\n",
    "        1. Reactive Agents: Respond to current perceptions\n",
    "        2. Model-based Agents: Maintain internal state\n",
    "        3. Goal-based Agents: Act to achieve specific objectives\n",
    "        4. Utility-based Agents: Optimize for maximum utility\n",
    "        \n",
    "        Key Components:\n",
    "        - Perception: Sensing the environment\n",
    "        - Decision Making: Choosing appropriate actions\n",
    "        - Action: Executing chosen behaviors\n",
    "        - Learning: Improving performance over time\n",
    "        \"\"\")\n",
    "    \n",
    "    # Sample JSON document\n",
    "    sample_json = {\n",
    "        \"agents\": [\n",
    "            {\n",
    "                \"name\": \"ChatGPT\",\n",
    "                \"type\": \"Language Model\",\n",
    "                \"capabilities\": [\"text generation\", \"question answering\", \"summarization\"],\n",
    "                \"developer\": \"OpenAI\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Mistral\",\n",
    "                \"type\": \"Language Model\", \n",
    "                \"capabilities\": [\"text generation\", \"reasoning\", \"multilingual\"],\n",
    "                \"developer\": \"Mistral AI\"\n",
    "            }\n",
    "        ],\n",
    "        \"rag_components\": [\n",
    "            \"Document Loading\",\n",
    "            \"Text Splitting\",\n",
    "            \"Embeddings\",\n",
    "            \"Vector Database\",\n",
    "            \"Retrieval\",\n",
    "            \"Generation\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(f\"{directory_path}/sample.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sample_json, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Created sample documents in {directory_path}/\")\n",
    "\n",
    "# Load documents\n",
    "documents = load_documents_from_directory()\n",
    "print(f\"\\nüìö Total documents loaded: {len(documents)}\")\n",
    "\n",
    "# Display first document as example\n",
    "if documents:\n",
    "    print(f\"\\nüìÑ First document preview:\")\n",
    "    print(f\"Source: {documents[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content (first 300 chars): {documents[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b916c3",
   "metadata": {},
   "source": [
    "## 4. Split Documents into Chunks\n",
    "\n",
    "Large documents need to be split into smaller chunks for effective retrieval. We'll use LangChain's text splitters to create manageable pieces while preserving context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38073b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Original documents: 1\n",
      "üî™ Document chunks after splitting: 1\n",
      "\n",
      "üìã Example chunk:\n",
      "Source: knowledgebase\\sample.txt\n",
      "Content: Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artificial intelligence agents.\n",
      "        \n",
      "        What are AI Agents?\n",
      "        AI agents are autonomous syste...\n"
     ]
    }
   ],
   "source": [
    "# Import text splitters\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Maximum characters per chunk\n",
    "    chunk_overlap=200,  # Overlap between chunks to preserve context\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Split on paragraphs, then lines, then words\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"üìÑ Original documents: {len(documents)}\")\n",
    "print(f\"üî™ Document chunks after splitting: {len(document_chunks)}\")\n",
    "\n",
    "# Display example chunk\n",
    "if document_chunks:\n",
    "    print(f\"\\nüìã Example chunk:\")\n",
    "    print(f\"Source: {document_chunks[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content: {document_chunks[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0b5cc",
   "metadata": {},
   "source": [
    "## 5. Create Embeddings and Vector Store\n",
    "\n",
    "To enable semantic search, we'll convert our text chunks into vector embeddings and store them in a vector database. We'll use HuggingFace embeddings and FAISS for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ce2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dekamb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dekamb\\AppData\\Local\\Temp\\ipykernel_35860\\4054164778.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "c:\\Users\\dekamb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\dekamb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\dekamb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dekamb\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\dekamb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dekamb\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Creating embeddings for document chunks...\n",
      "‚úÖ Vector store created with 1 embedded chunks\n",
      "\n",
      "üîç Testing similarity search for: 'What are AI agents?'\n",
      "Found 1 similar documents:\n",
      "\n",
      "1. Source: knowledgebase\\sample.txt\n",
      "   Content: Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artificial intelligence agents.\n",
      "        \n",
      "        What are...\n",
      "‚úÖ Vector store created with 1 embedded chunks\n",
      "\n",
      "üîç Testing similarity search for: 'What are AI agents?'\n",
      "Found 1 similar documents:\n",
      "\n",
      "1. Source: knowledgebase\\sample.txt\n",
      "   Content: Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artificial intelligence agents.\n",
      "        \n",
      "        What are...\n"
     ]
    }
   ],
   "source": [
    "# Import embedding and vector store components\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Fast and effective model\n",
    "    model_kwargs={'device': 'cpu'}  # Use CPU (change to 'cuda' if you have GPU)\n",
    ")\n",
    "\n",
    "print(\"üî¢ Creating embeddings for document chunks...\")\n",
    "\n",
    "# Create vector store from documents\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Vector store created with {len(document_chunks)} embedded chunks\")\n",
    "\n",
    "# Test similarity search\n",
    "test_query = \"What are AI agents?\"\n",
    "similar_docs = vector_store.similarity_search(test_query, k=3)\n",
    "\n",
    "print(f\"\\nüîç Testing similarity search for: '{test_query}'\")\n",
    "print(f\"Found {len(similar_docs)} similar documents:\")\n",
    "for i, doc in enumerate(similar_docs, 1):\n",
    "    print(f\"\\n{i}. Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   Content: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c25bd4",
   "metadata": {},
   "source": [
    "## 6. Create RAG Chain\n",
    "\n",
    "Now we'll combine retrieval and generation by creating a RAG chain that can answer questions based on our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e45f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG chain created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import RAG components\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create retriever from vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # Retrieve top 4 most relevant chunks\n",
    ")\n",
    "\n",
    "# Create custom prompt template for RAG\n",
    "rag_prompt_template = \"\"\"\n",
    "You are a helpful assistant that answers questions based on the provided context.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer based on the context, just say that you don't know.\n",
    "Don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=rag_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": RAG_PROMPT}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e61b9",
   "metadata": {},
   "source": [
    "## 7. Test RAG System\n",
    "\n",
    "Let's test our RAG system with various questions to see how it retrieves relevant information and generates answers based on our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e391453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Question: What are AI agents?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What are the different types of AI agents?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What are the different types of AI agents?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: Based on the provided context, the different types of AI agents are:\n",
      "\n",
      "1. Reactive Agents: Respond to current perceptions\n",
      "2. Model-based Agents: Maintain internal state\n",
      "3. Goal-based Agents: Act to achieve specific objectives\n",
      "4. Utility-based Agents: Optimize for maximum utility\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What capabilities does Mistral have?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: Based on the provided context, the different types of AI agents are:\n",
      "\n",
      "1. Reactive Agents: Respond to current perceptions\n",
      "2. Model-based Agents: Maintain internal state\n",
      "3. Goal-based Agents: Act to achieve specific objectives\n",
      "4. Utility-based Agents: Optimize for maximum utility\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What capabilities does Mistral have?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: I don't know. The provided context does not contain any information about Mistral or its capabilities.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What are the components of RAG?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: I don't know. The provided context does not contain any information about Mistral or its capabilities.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: What are the components of RAG?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: I don't know. The provided context does not contain any information about RAG or its components.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: How do AI agents perceive their environment?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: I don't know. The provided context does not contain any information about RAG or its components.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§î Question: How do AI agents perceive their environment?\n",
      "--------------------------------------------------\n",
      "ü§ñ Answer: AI agents perceive their environment through the **Perception** component, which involves sensing the environment. This allows them to gather information and respond accordingly.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Answer: AI agents perceive their environment through the **Perception** component, which involves sensing the environment. This allows them to gather information and respond accordingly.\n",
      "\n",
      "üìö Sources used (1 documents):\n",
      "1. knowledgebase\\sample.txt - Welcome to the AI Agents Tutorial!\n",
      "        \n",
      "        This document contains information about artific...\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG system with various questions\n",
    "\n",
    "def test_rag_system(question):\n",
    "    \"\"\"Test the RAG system with a question and display results\"\"\"\n",
    "    print(f\"ü§î Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get answer from RAG chain\n",
    "    result = rag_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(f\"ü§ñ Answer: {result['result']}\")\n",
    "    print(f\"\\nüìö Sources used ({len(result['source_documents'])} documents):\")\n",
    "    \n",
    "    for i, doc in enumerate(result['source_documents'], 1):\n",
    "        print(f\"{i}. {doc.metadata.get('source', 'Unknown')} - {doc.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    return result\n",
    "\n",
    "# Test with different types of questions\n",
    "test_questions = [\n",
    "    \"What are AI agents?\",\n",
    "    \"What are the different types of AI agents?\",\n",
    "    \"What capabilities does Mistral have?\",\n",
    "    \"What are the components of RAG?\",\n",
    "    \"How do AI agents perceive their environment?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    test_rag_system(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610fbb9",
   "metadata": {},
   "source": [
    "## 8. Interactive RAG Demo\n",
    "\n",
    "Let's create an interactive function where you can ask questions about your documents and get real-time answers with source attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8127893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Interactive RAG Demo\n",
      "\n",
      "ü§î Question: What are the key components of AI agents?\n",
      "ü§ñ Answer: The key components of AI agents are:\n",
      "\n",
      "- Perception: Sensing the environment\n",
      "- Decision Making: Choosing appropriate actions\n",
      "- Action: Executing chosen behaviors\n",
      "- Learning: Improving performance over time\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ü§î Question: What are the key components of AI agents?\n",
      "ü§ñ Answer: The key components of AI agents are:\n",
      "\n",
      "- Perception: Sensing the environment\n",
      "- Decision Making: Choosing appropriate actions\n",
      "- Action: Executing chosen behaviors\n",
      "- Learning: Improving performance over time\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ü§î Question: Can you explain the different types of AI agents?\n",
      "ü§ñ Answer: Based on the provided context, here are the different types of AI agents:\n",
      "\n",
      "1. **Reactive Agents**: These agents respond to current perceptions without relying on past experiences or maintaining an internal state.\n",
      "2. **Model-based Agents**: These agents maintain an internal state or model of the world to make decisions based on their understanding of the environment.\n",
      "3. **Goal-based Agents**: These agents act to achieve specific objectives or goals, guiding their decision-making process.\n",
      "4. **Utility-based Agents**: These agents optimize their actions to achieve the maximum utility or benefit, often balancing multiple objectives.\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ü§î Question: Can you explain the different types of AI agents?\n",
      "ü§ñ Answer: Based on the provided context, here are the different types of AI agents:\n",
      "\n",
      "1. **Reactive Agents**: These agents respond to current perceptions without relying on past experiences or maintaining an internal state.\n",
      "2. **Model-based Agents**: These agents maintain an internal state or model of the world to make decisions based on their understanding of the environment.\n",
      "3. **Goal-based Agents**: These agents act to achieve specific objectives or goals, guiding their decision-making process.\n",
      "4. **Utility-based Agents**: These agents optimize their actions to achieve the maximum utility or benefit, often balancing multiple objectives.\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ü§î Question: What information do you have about Mistral AI?\n",
      "ü§ñ Answer: I don't know. The provided context only contains information about AI agents in general and does not mention Mistral AI.\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ü§î Question: What information do you have about Mistral AI?\n",
      "ü§ñ Answer: I don't know. The provided context only contains information about AI agents in general and does not mention Mistral AI.\n",
      "\n",
      "üìö Sources:\n",
      "  1. knowledgebase\\sample.txt: Welcome to the AI Agents Tutorial!                  This document contains information about artificial intelligence agents.                  What are...\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interactive RAG function\n",
    "def ask_question(question, show_sources=True):\n",
    "    \"\"\"\n",
    "    Ask a question to the RAG system and get an answer with optional source display\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = rag_chain.invoke({\"query\": question})\n",
    "        \n",
    "        print(f\"ü§î Question: {question}\")\n",
    "        print(f\"ü§ñ Answer: {result['result']}\")\n",
    "        \n",
    "        if show_sources:\n",
    "            print(f\"\\nüìö Sources:\")\n",
    "            for i, doc in enumerate(result['source_documents'], 1):\n",
    "                source_file = doc.metadata.get('source', 'Unknown')\n",
    "                content_preview = doc.page_content[:150].replace('\\n', ' ')\n",
    "                print(f\"  {i}. {source_file}: {content_preview}...\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Try some example questions\n",
    "print(\"üöÄ Interactive RAG Demo\\n\")\n",
    "\n",
    "# Example 1: General question about AI agents\n",
    "ask_question(\"What are the key components of AI agents?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 2: Specific question about types\n",
    "ask_question(\"Can you explain the different types of AI agents?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 3: Question about specific technology\n",
    "ask_question(\"What information do you have about Mistral AI?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# You can now use ask_question(\"Your question here\") to test with your own questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca003f1",
   "metadata": {},
   "source": [
    "## 9. Advanced RAG Features\n",
    "\n",
    "Let's explore some advanced features like conversation memory and hybrid search to make our RAG system more sophisticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f0278b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversational RAG system created!\n",
      "\n",
      "üó£Ô∏è Conversational RAG Demo:\n",
      "==================================================\n",
      "ü§î You: What are AI agents?\n",
      "ü§ñ RAG: AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "------------------------------\n",
      "\n",
      "ü§î You: What are AI agents?\n",
      "ü§ñ RAG: AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "------------------------------\n",
      "\n",
      "ü§î You: Can you give me more details about the reactive type?\n",
      "ü§ñ RAG: Reactive AI agents operate based solely on the current input they receive from their environment without relying on any internal memory or historical data. These agents follow the principle of the \"condition-action\" rule, meaning they respond to immediate perceptions with predetermined actions. Reactive agents are typically simpler in design and are effective in environments where quick responses are crucial, and the complexity of decision-making is relatively low. They do not consider the history of past actions or states, which makes them less capable of handling tasks that require understanding or planning over time. Examples of reactive agents include simple robotic systems that perform repetitive tasks or basic chatbots that provide predefined responses to specific user inputs.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "------------------------------\n",
      "\n",
      "ü§î You: Can you give me more details about the reactive type?\n",
      "ü§ñ RAG: Reactive AI agents operate based solely on the current input they receive from their environment without relying on any internal memory or historical data. These agents follow the principle of the \"condition-action\" rule, meaning they respond to immediate perceptions with predetermined actions. Reactive agents are typically simpler in design and are effective in environments where quick responses are crucial, and the complexity of decision-making is relatively low. They do not consider the history of past actions or states, which makes them less capable of handling tasks that require understanding or planning over time. Examples of reactive agents include simple robotic systems that perform repetitive tasks or basic chatbots that provide predefined responses to specific user inputs.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "------------------------------\n",
      "\n",
      "ü§î You: How do they differ from goal-based agents?\n",
      "ü§ñ RAG: Reactive AI agents respond to immediate perceptions of their environment without maintaining any internal state or memory of past events. They operate based on a set of predefined rules that map perceptions directly to actions.\n",
      "\n",
      "In contrast, goal-based agents act to achieve specific objectives or goals. These agents have a more complex decision-making process that involves evaluating different actions based on how well they contribute to achieving the goal. Goal-based agents may use planning and problem-solving techniques to determine the best course of action.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "üéØ Notice how the system maintains context across questions!\n",
      "ü§î You: How do they differ from goal-based agents?\n",
      "ü§ñ RAG: Reactive AI agents respond to immediate perceptions of their environment without maintaining any internal state or memory of past events. They operate based on a set of predefined rules that map perceptions directly to actions.\n",
      "\n",
      "In contrast, goal-based agents act to achieve specific objectives or goals. These agents have a more complex decision-making process that involves evaluating different actions based on how well they contribute to achieving the goal. Goal-based agents may use planning and problem-solving techniques to determine the best course of action.\n",
      "üìö Sources: 1 documents referenced\n",
      "\n",
      "üéØ Notice how the system maintains context across questions!\n"
     ]
    }
   ],
   "source": [
    "# Advanced RAG with conversation memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Set up conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "# Create conversational RAG chain\n",
    "conversational_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Conversational RAG system created!\")\n",
    "\n",
    "# Test conversational capabilities\n",
    "def chat_with_rag(message):\n",
    "    \"\"\"Chat with the RAG system maintaining conversation history\"\"\"\n",
    "    try:\n",
    "        result = conversational_rag.invoke({\"question\": message})\n",
    "        print(f\"ü§î You: {message}\")\n",
    "        print(f\"ü§ñ RAG: {result['answer']}\")\n",
    "        \n",
    "        # Show sources for transparency\n",
    "        if result.get('source_documents'):\n",
    "            print(f\"üìö Sources: {len(result['source_documents'])} documents referenced\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Demonstrate conversation flow\n",
    "print(\"\\nüó£Ô∏è Conversational RAG Demo:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# First question\n",
    "chat_with_rag(\"What are AI agents?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# Follow-up question (should use context from previous)\n",
    "chat_with_rag(\"Can you give me more details about the reactive type?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# Another follow-up\n",
    "chat_with_rag(\"How do they differ from goal-based agents?\")\n",
    "\n",
    "print(\"\\nüéØ Notice how the system maintains context across questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817c79a",
   "metadata": {},
   "source": [
    "## 10. Wrap-up: RAG System Architecture\n",
    "\n",
    "In this notebook, we've built a comprehensive **RAG (Retrieval-Augmented Generation) System** with LangChain and Mistral:\n",
    "\n",
    "**Key Components Implemented:**\n",
    "- **Document Loading**: Multi-format document ingestion (PDF, DOCX, TXT, JSON, CSV)\n",
    "- **Text Splitting**: Intelligent chunking with overlap for context preservation\n",
    "- **Embeddings**: Semantic vector representations using HuggingFace models\n",
    "- **Vector Store**: FAISS for fast similarity search and retrieval\n",
    "- **RAG Chain**: Integration of retrieval and generation with Mistral LLM\n",
    "- **Conversational Memory**: Context-aware multi-turn conversations\n",
    "\n",
    "**RAG Workflow:**\n",
    "1. **Ingestion**: Load and split documents into chunks\n",
    "2. **Embedding**: Convert chunks to vector representations\n",
    "3. **Storage**: Store embeddings in vector database\n",
    "4. **Retrieval**: Find relevant chunks based on query similarity\n",
    "5. **Generation**: Generate answers using retrieved context and LLM\n",
    "6. **Response**: Return answer with source attribution\n",
    "\n",
    "**Next Steps:**\n",
    "- **Enhanced Retrieval**: Implement hybrid search (semantic + keyword)\n",
    "- **Advanced Chunking**: Use semantic chunking strategies\n",
    "- **Multi-modal RAG**: Add support for images and other media\n",
    "- **Evaluation**: Implement RAG evaluation metrics (RAGAS, etc.)\n",
    "- **Production**: Deploy with FastAPI and add caching\n",
    "\n",
    "**Benefits of RAG:**\n",
    "- Access to current, domain-specific information\n",
    "- Reduced hallucination through grounded responses\n",
    "- Source attribution for transparency\n",
    "- Scalable knowledge base updates\n",
    "\n",
    "This RAG system provides a solid foundation for building knowledge-aware AI applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
